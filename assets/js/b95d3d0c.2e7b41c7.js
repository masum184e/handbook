"use strict";(globalThis.webpackChunkhandbook=globalThis.webpackChunkhandbook||[]).push([[8557],{28453(e,n,t){t.d(n,{R:()=>c,x:()=>a});var s=t(96540);const r={},i=s.createContext(r);function c(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),s.createElement(i.Provider,{value:n},e.children)}},42806(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"system-design/Latency/Latency","title":"Latency","description":"Latency in system design refers to the time it takes for a request to travel from the client to the server and back with a response. It is a key performance metric that reflects how responsive a system is.","source":"@site/docs/system-design/12. Latency/1. Latency.md","sourceDirName":"system-design/12. Latency","slug":"/system-design/Latency/Latency","permalink":"/handbook/docs/system-design/Latency/Latency","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"systemDesignSidebar","previous":{"title":"Queue","permalink":"/handbook/docs/system-design/Queue"},"next":{"title":"Tail Latency","permalink":"/handbook/docs/system-design/Latency/Tail Latency"}}');var r=t(74848),i=t(28453);const c={},a=void 0,l={},o=[{value:"Types of Latency",id:"types-of-latency",level:2},{value:"Why Latency Matters",id:"why-latency-matters",level:2},{value:"Latency Breakdown",id:"latency-breakdown",level:2},{value:"Example of Latency",id:"example-of-latency",level:2},{value:"How to Reduce Latency",id:"how-to-reduce-latency",level:2}];function d(e){const n={code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"Latency in system design refers to the time it takes for a request to travel from the client to the server and back with a response. It is a key performance metric that reflects how responsive a system is."}),"\n",(0,r.jsx)(n.h2,{id:"types-of-latency",children:"Types of Latency"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Network Latency:"})," Time taken for data to travel across the network(optical cable) from client to server and back."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Processing Latency:"})," Time taken by the server or application to process a request."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Queueing Latency:"})," Time a request waits in a queue before being processed (e.g., due to load, rate limits, etc.)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Disk I/O Latency:"})," Time required to read/write data from storage systems."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Database Latency:"})," Time taken to query the database and return the result."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"why-latency-matters",children:"Why Latency Matters"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"User Experience (slower pages, timeouts)"}),"\n",(0,r.jsx)(n.li,{children:"System Throughput"}),"\n",(0,r.jsx)(n.li,{children:"Real-time systems (e.g., video conferencing, trading platforms)"}),"\n",(0,r.jsx)(n.li,{children:"Scalability"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"latency-breakdown",children:"Latency Breakdown"}),"\n",(0,r.jsx)(n.p,{children:"Let\u2019s assume a web app that fetches user data:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"Client <--\x3e API Server <--\x3e Database\n"})}),"\n",(0,r.jsx)(n.p,{children:"Typical latency breakdown might look like:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Network: 50ms (client to server)"}),"\n",(0,r.jsx)(n.li,{children:"Processing: 20ms"}),"\n",(0,r.jsx)(n.li,{children:"DB Query: 100ms"}),"\n",(0,r.jsx)(n.li,{children:"Response Time: 50ms (back to client)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Total Latency: ~220ms"}),"\n",(0,r.jsx)(n.h2,{id:"example-of-latency",children:"Example of Latency"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'const express = require("express");\r\nconst app = express();\r\n\r\nconst port = 3000;\r\n\r\n// Simulated DB query with delay\r\nfunction fakeDBQuery(userId) {\r\n  return new Promise((resolve) => {\r\n    setTimeout(() => {\r\n      resolve({ id: userId, name: "Masum Billah", role: "Admin" });\r\n    }, 100); // 100ms DB latency\r\n  });\r\n}\r\n\r\napp.get("/user/:id", async (req, res) => {\r\n  const start = Date.now(); // Start timer\r\n\r\n  const user = await fakeDBQuery(req.params.id);\r\n\r\n  const end = Date.now(); // End timer\r\n  const latency = end - start;\r\n\r\n  res.json({\r\n    user,\r\n    latency: `${latency}ms`, // Show total processing latency\r\n  });\r\n});\r\n\r\napp.listen(port, () => {\r\n  console.log(`Server running on http://localhost:${port}`);\r\n});\n'})}),"\n",(0,r.jsx)(n.h2,{id:"how-to-reduce-latency",children:"How to Reduce Latency"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Area"}),(0,r.jsx)(n.th,{children:"Techniques"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Network"})}),(0,r.jsx)(n.td,{children:"Use CDNs, HTTP/2, minimize payload size"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Processing"})}),(0,r.jsx)(n.td,{children:"Optimize algorithms, reduce blocking code"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Database"})}),(0,r.jsx)(n.td,{children:"Use indexes, caching (e.g., Redis), optimize queries"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Queueing"})}),(0,r.jsx)(n.td,{children:"Add workers, increase concurrency"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Architecture"})}),(0,r.jsx)(n.td,{children:"Use microservices, load balancers, edge servers"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Caching"})}),(0,r.jsx)(n.td,{children:"Avoid repeated DB queries"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Load Balancer"})}),(0,r.jsx)(n.td,{children:"Distribute traffic"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Rate limiting"})}),(0,r.jsx)(n.td,{children:"Throttle excessive calls"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Try to achieve 100ms latency."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);