"use strict";(globalThis.webpackChunkhandbook=globalThis.webpackChunkhandbook||[]).push([[64685],{28453(e,s,t){t.d(s,{R:()=>i,x:()=>a});var n=t(96540);const r={},c=n.createContext(r);function i(e){const s=n.useContext(c);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),n.createElement(c.Provider,{value:s},e.children)}},64479(e,s,t){t.r(s),t.d(s,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"system-design/Latency/Memory Access Latency","title":"Memory Access Latency","description":"Memory access latency is the time delay between issuing a memory request (read/write) and the moment the data is available to the processor or system component. It is measured in nanoseconds (ns) or CPU cycles, and it plays a critical role in performance-sensitive applications such as databases, in-memory systems, or low-latency services.","source":"@site/docs/system-design/12. Latency/4. Memory Access Latency.md","sourceDirName":"system-design/12. Latency","slug":"/system-design/Latency/Memory Access Latency","permalink":"/handbook/docs/system-design/Latency/Memory Access Latency","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"systemDesignSidebar","previous":{"title":"Network Latency","permalink":"/handbook/docs/system-design/Latency/Network Latency"},"next":{"title":"Disk Access Latency","permalink":"/handbook/docs/system-design/Latency/Disk Access Latency"}}');var r=t(74848),c=t(28453);const i={},a=void 0,d={},l=[{value:"Memory Hierarchy &amp; Latency",id:"memory-hierarchy--latency",level:2},{value:"Why Memory Latency Matters",id:"why-memory-latency-matters",level:2},{value:"Optimization Techniques for Memory Latency",id:"optimization-techniques-for-memory-latency",level:2},{value:"Example with In-Memory Database",id:"example-with-in-memory-database",level:2}];function o(e){const s={h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,c.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.p,{children:"Memory access latency is the time delay between issuing a memory request (read/write) and the moment the data is available to the processor or system component. It is measured in nanoseconds (ns) or CPU cycles, and it plays a critical role in performance-sensitive applications such as databases, in-memory systems, or low-latency services."}),"\n",(0,r.jsx)(s.h2,{id:"memory-hierarchy--latency",children:"Memory Hierarchy & Latency"}),"\n",(0,r.jsx)(s.p,{children:"Modern systems use a hierarchical memory model to balance speed, capacity, and cost."}),"\n",(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Memory Type"}),(0,r.jsx)(s.th,{children:"Latency (approx)"}),(0,r.jsx)(s.th,{children:"Size (typical)"}),(0,r.jsx)(s.th,{children:"Location"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"CPU Register"}),(0,r.jsx)(s.td,{children:"0.25 ns"}),(0,r.jsx)(s.td,{children:"Bytes"}),(0,r.jsx)(s.td,{children:"On CPU"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"L1 Cache"}),(0,r.jsx)(s.td,{children:"0.5 \u2013 1 ns"}),(0,r.jsx)(s.td,{children:"~32 KB"}),(0,r.jsx)(s.td,{children:"On CPU core"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"L2 Cache"}),(0,r.jsx)(s.td,{children:"3 \u2013 10 ns"}),(0,r.jsx)(s.td,{children:"~256 KB"}),(0,r.jsx)(s.td,{children:"On CPU chip"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"L3 Cache"}),(0,r.jsx)(s.td,{children:"10 \u2013 30 ns"}),(0,r.jsx)(s.td,{children:"~8 MB"}),(0,r.jsx)(s.td,{children:"Shared on chip"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"RAM (DRAM)"}),(0,r.jsx)(s.td,{children:"50 \u2013 100 ns"}),(0,r.jsx)(s.td,{children:"~GBs"}),(0,r.jsx)(s.td,{children:"On motherboard"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"SSD Storage"}),(0,r.jsx)(s.td,{children:"50 \u2013 150 \u03bcs"}),(0,r.jsx)(s.td,{children:"~TBs"}),(0,r.jsx)(s.td,{children:"PCIe/SATA device"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"HDD"}),(0,r.jsx)(s.td,{children:"5 \u2013 10 ms"}),(0,r.jsx)(s.td,{children:"~TBs"}),(0,r.jsx)(s.td,{children:"External disk"})]})]})]}),"\n",(0,r.jsx)(s.p,{children:"As we move down the hierarchy, latency increases and cost per byte decreases."}),"\n",(0,r.jsx)(s.h2,{id:"why-memory-latency-matters",children:"Why Memory Latency Matters"}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsx)(s.li,{children:"CPU is faster than memory \u2192 Even small delays stall execution."}),"\n",(0,r.jsx)(s.li,{children:"I/O-bound vs Memory-bound \u2192 High latency increases wait time."}),"\n",(0,r.jsx)(s.li,{children:"Performance bottlenecks \u2192 Especially in high-throughput systems."}),"\n",(0,r.jsx)(s.li,{children:"Cache misses lead to expensive memory fetches \u2192 Cache-efficient code matters."}),"\n"]}),"\n",(0,r.jsx)(s.h2,{id:"optimization-techniques-for-memory-latency",children:"Optimization Techniques for Memory Latency"}),"\n",(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Strategy"}),(0,r.jsx)(s.th,{children:"Description"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Caching"})}),(0,r.jsx)(s.td,{children:"Store frequently accessed data in faster memory"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Prefetching"})}),(0,r.jsx)(s.td,{children:"Predict and load future memory needs ahead of time"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Memory locality"})}),(0,r.jsx)(s.td,{children:"Improve access patterns (e.g., access arrays sequentially)"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Data alignment"})}),(0,r.jsx)(s.td,{children:"Structure data to fit cache lines better"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Avoiding cache thrashing"})}),(0,r.jsx)(s.td,{children:"Reduce conflicts in cache sets by designing access-friendly structures"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"NUMA-awareness"})}),(0,r.jsx)(s.td,{children:"Place data close to the CPU core using it in NUMA systems"})]})]})]}),"\n",(0,r.jsx)(s.h2,{id:"example-with-in-memory-database",children:"Example with In-Memory Database"}),"\n",(0,r.jsx)(s.p,{children:"Scenario: A real-time analytics service stores data in memory (Redis, Memcached)."}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Accessing hot data in CPU cache: ~1\u20135 ns (very fast)"}),"\n",(0,r.jsx)(s.li,{children:"Accessing cold data in RAM: ~100 ns (20\xd7 slower)"}),"\n",(0,r.jsx)(s.li,{children:"Accessing persisted data in SSD (fallback): ~100,000 ns = 100 \u03bcs"}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,c.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}}}]);