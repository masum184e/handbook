"use strict";(globalThis.webpackChunkhandbook=globalThis.webpackChunkhandbook||[]).push([[15643],{28453(e,s,n){n.d(s,{R:()=>i,x:()=>l});var t=n(96540);const a={},r=t.createContext(a);function i(e){const s=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),t.createElement(r.Provider,{value:s},e.children)}},77157(e,s,n){n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"system-design/Latency/Tail Latency","title":"Tail Latency","description":"Tail latency refers to the high-end response times (or delays) experienced by a small percentage of requests in a system \u2014 usually the slowest 1%, 0.1%, or even 0.01% of requests.","source":"@site/docs/system-design/12. Latency/2. Tail Latency.md","sourceDirName":"system-design/12. Latency","slug":"/system-design/Latency/Tail Latency","permalink":"/handbook/docs/system-design/Latency/Tail Latency","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"systemDesignSidebar","previous":{"title":"Latency","permalink":"/handbook/docs/system-design/Latency/Latency"},"next":{"title":"Network Latency","permalink":"/handbook/docs/system-design/Latency/Network Latency"}}');var a=n(74848),r=n(28453);const i={},l=void 0,c={},o=[{value:"Why Tail Latency Matters",id:"why-tail-latency-matters",level:2},{value:"Analogy of Tail Latency",id:"analogy-of-tail-latency",level:2},{value:"Example of Tail Latency",id:"example-of-tail-latency",level:2},{value:"Example Tail Latency Data",id:"example-tail-latency-data",level:3},{value:"How to Reduce Tail Latency",id:"how-to-reduce-tail-latency",level:2}];function d(e){const s={code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.p,{children:"Tail latency refers to the high-end response times (or delays) experienced by a small percentage of requests in a system \u2014 usually the slowest 1%, 0.1%, or even 0.01% of requests."}),"\n",(0,a.jsx)(s.p,{children:"For example, p99 latency means the 99th percentile latency \u2014 99% of requests are faster than this value, but 1% are slower. That slowest 1% is called the tail."}),"\n",(0,a.jsx)("img",{src:"https://robertovitillo.com/why-you-should-measure-tail-latencies/distribution.png"}),"\n",(0,a.jsx)(s.h2,{id:"why-tail-latency-matters",children:"Why Tail Latency Matters"}),"\n",(0,a.jsx)(s.p,{children:"Even if your system handles most requests quickly, a few very slow responses can:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"Ruin user experience (especially in real-time apps)."}),"\n",(0,a.jsx)(s.li,{children:"Cascade delays in distributed systems (e.g., microservices)."}),"\n",(0,a.jsx)(s.li,{children:"Impact SLAs (Service Level Agreements)."}),"\n",(0,a.jsx)(s.li,{children:"Break systems relying on aggregation (e.g., waiting for 10 services to respond)."}),"\n"]}),"\n",(0,a.jsx)(s.h2,{id:"analogy-of-tail-latency",children:"Analogy of Tail Latency"}),"\n",(0,a.jsx)(s.p,{children:"Imagine you're at a fast-food restaurant:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"95% of customers are served within 2 minutes."}),"\n",(0,a.jsx)(s.li,{children:"But the last 5% are waiting 10 minutes because their food is more complex.\r\nEven if the average time is good, the long waits for the unlucky few are frustrating and degrade trust."}),"\n"]}),"\n",(0,a.jsx)(s.h2,{id:"example-of-tail-latency",children:"Example of Tail Latency"}),"\n",(0,a.jsx)(s.p,{children:"Suppose you have a Node.js server handling API requests and fetching data from 3 microservices in parallel. Here's the bottleneck:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-js",children:'const express = require("express");\r\nconst axios = require("axios");\r\nconst app = express();\r\n\r\napp.get("/aggregate", async (req, res) => {\r\n  try {\r\n    const [serviceA, serviceB, serviceC] = await Promise.all([\r\n      axios.get("http://service-a/data"),\r\n      axios.get("http://service-b/data"),\r\n      axios.get("http://service-c/data"),\r\n    ]);\r\n    res.send({\r\n      a: serviceA.data,\r\n      b: serviceB.data,\r\n      c: serviceC.data,\r\n    });\r\n  } catch (err) {\r\n    res.status(500).send("Error aggregating data");\r\n  }\r\n});\r\n\r\napp.listen(3000, () => console.log("API running"));\n'})}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"3 services are called in parallel."}),"\n",(0,a.jsx)(s.li,{children:"If 1 of them is slow (e.g., has a p99 latency of 3 seconds), the whole endpoint waits."}),"\n",(0,a.jsx)(s.li,{children:"This causes tail latency propagation."}),"\n"]}),"\n",(0,a.jsx)(s.h3,{id:"example-tail-latency-data",children:"Example Tail Latency Data"}),"\n",(0,a.jsxs)(s.table,{children:[(0,a.jsx)(s.thead,{children:(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.th,{children:"Percentile"}),(0,a.jsx)(s.th,{children:"Latency (ms)"})]})}),(0,a.jsxs)(s.tbody,{children:[(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"p50"}),(0,a.jsx)(s.td,{children:"100"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"p90"}),(0,a.jsx)(s.td,{children:"200"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"p99"}),(0,a.jsx)(s.td,{children:"3000"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"p99.9"}),(0,a.jsx)(s.td,{children:"8000"})]})]})]}),"\n",(0,a.jsx)(s.p,{children:"You can see that while most users experience sub-200ms responses, a few users get multi-second delays, causing a bad experience."}),"\n",(0,a.jsx)(s.h2,{id:"how-to-reduce-tail-latency",children:"How to Reduce Tail Latency"}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Timeouts & Fallbacks:"})," Set timeouts for slow services and return cached/stale/partial data:"]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-js",children:"const axiosWithTimeout = axios.create({ timeout: 500 });\n"})}),"\n",(0,a.jsxs)(s.ol,{start:"2",children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Redundancy / Hedging Requests:"})," Send requests to multiple replicas and use the fastest response."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Load Balancing:"})," Avoid overloading specific servers that are slower."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Isolate Slow Paths:"})," Identify slow services and split critical/fast and slow/non-critical paths."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Queue Management:"})," Use back-pressure and queues to avoid unbounded waiting."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Monitor p95/p99 metrics"})," not just average latency."]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);