{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaeeabcb-c25b-4ec3-b67b-dc041ff79e55",
   "metadata": {},
   "source": [
    "# Language Model\n",
    "\n",
    "Language Model is a computer program that analyze a given sequence of words and provide a basis for their word prediction. Language model is used in AI, NLP, NLU, NLG system, particularly ones that perform text generation, machine translation and question answering.\n",
    "\n",
    "__LLM - Large Language Model__ are are designed to understand and generate human language at scale. **GPT**, **BERT**.\n",
    "\n",
    "__MLM - Masked Language Model__ are a specific type of language model that predicts masked or hidden or blank words in a sentence.\n",
    "\n",
    "__CLM - Casual Language Model__ generate text sequentially, one token at a time, based only on the tokens that came before it in the input sequence. It basically predict next word based on previous word\n",
    "\n",
    "Here's how a typical language model works:\n",
    "\n",
    "1. *Input:* The process starts with the user providing input in the form of text. This input can be a question, a prompt for generating text, or any other form of communication.\n",
    "\n",
    "2. *Tokenization:* The input text is split into smaller units called tokens. These tokens could be words, subwords, or even characters, depending on the model architecture and tokenization strategy used.\n",
    "\n",
    "3. *Embedding:* Each token is then converted into a numerical representation called word embeddings or token embeddings. These embeddings capture the semantic meaning of the tokens and their relationships with other tokens.\n",
    "\n",
    "4. *Processing:* The embeddings of the tokens are fed into the model's neural network architecture. This network consists of multiple layers of processing units (neurons) that transform the input embeddings through various mathematical operations.\n",
    "\n",
    "5. *Contextual Understanding:* As the input propagate through the network, the model learns to understand the contextual relationships between the tokens. It allow the model to focus on relevant parts of the input.\n",
    "\n",
    "6. *Prediction:* Based on its understanding of the input text and the context provided, the model generates a response. \n",
    "\n",
    "7. *Output:* The model outputs the predicted tokens, which can be used to generate text or to perform other tasks such as text classification, translation, or summarization.\n",
    "\n",
    "# Large Language Model\n",
    "Large language model is a machine learning model designed to understand, generate, and manipulate human language on a vast scale. These models are typically built using deep learning techniques, especially variants of the transformer architecture, and are trained on massive datasets of text from the internet and other sources.\n",
    "\n",
    "# Generative AI\n",
    "Generative AI refers to deep-learning models that can generate high-quality text, images, and other content based on the data they were trained on.\n",
    "\n",
    "## Quick Information\n",
    "- GPT(Generative Pre-trained Transformer) is a series of llm developed by OpenAI\n",
    "- ChatGPT is a generative AI specifically fine-tuned for conversational interactions.\n",
    "- OpenAI's work best with JSON while Anthropic's models work best with XML.\n",
    "\n",
    "# Langchain\n",
    "LangChain is an open source framework for building applications based on large language models (LLMs). It provides tools and abstractions to improve the customization, accuracy, and relevancy of the information the models generate. Basically it integrate ai(LLm model) with web/mobile applications. By abstracting complexities, it simplifies the process compared to direct integration, making it more accessible and manageable. The core element of any language model application is...the model. LangChain gives you the building blocks to interface with any language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e2339-c533-4c01-bff6-d8764c50a90d",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6018cd1-1df1-44d4-a75a-3798e0f758b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed616e-3c49-4d49-8526-41199f900cc4",
   "metadata": {},
   "source": [
    "# Model\n",
    "Language models in LangChain come in two flavors:\n",
    "\n",
    "__ChatModels:__ The ChatModel objects take a list of messages as input and output a message. Chat models are often backed by LLMs but tuned specifically for having conversations. \n",
    "\n",
    "__LLM:__ LLMs in LangChain refer to pure text completion models. The LLM objects take string as input and output string. OpenAI's GPT-3 is implemented as an LLM.\n",
    "\n",
    "The LLM returns a string, while the ChatModel returns a message. The main difference between them is their input and output schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced32722-3843-4573-8bd6-e692f12eaa04",
   "metadata": {},
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dda141-2ad8-45a6-95b5-f335418bc2c0",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5461e-7a4e-4b2e-ab34-1fdbdd682487",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-huggingface huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd6d1b-6212-465f-b433-6508296839bf",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741969d1-8acf-4ef2-96ae-f43bcde3c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "huggingfacehub_api_token = \"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\"\n",
    "llm = HuggingFaceEndpoint(repo_id = repo_id, huggingfacehub_api_token = huggingfacehub_api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabfdc99-5575-46f5-ae96-cf68cf0d2262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: \n",
      "\n",
      "1. Socktacular\n",
      "2. Vibrant Soles\n",
      "3. Rainbow Runners\n",
      "4. Kaleidosock\n",
      "5. Socktivity\n",
      "6. Chroma Socks\n",
      "7. Sock Candy Co.\n",
      "8. Pop Socks\n",
      "9. Colorful Kicks\n",
      "10. Sock Society\n",
      "11. Bright Sock Co.\n",
      "12. Sock Wonders\n",
      "13. Hue Socks\n",
      "14. Pizzaz Socks\n",
      "15. Sockcessories\n",
      "16. Sockaroo\n",
      "17. Socktacularity\n",
      "18. Sockstars\n",
      "19. Vibrant Vibes Socks\n",
      "20. SockPop\n",
      "21. Sockspectacular\n",
      "22. Sockalicious\n",
      "23. Socktacularity\n",
      "24. Socktacularity Co.\n",
      "25. Socktacularity Socks\n",
      "26. Socktacularity Designs\n",
      "27. Socktacularity Shop\n",
      "28. Socktacularity Collection\n",
      "29. Socktacularity Boutique\n",
      "30. Socktacularity Studio\n",
      "31. Socktacularity Gallery\n",
      "32. Socktacularity Emporium\n",
      "33. Socktacularity Bazaar\n",
      "34. Socktacularity Showroom\n",
      "35. Socktacularity Workshop\n",
      "36. Socktacularity Creative\n",
      "37. Socktacularity Artistry\n",
      "38. Socktacularity Studio Co.\n",
      "39. Socktacularity Gallery Co.\n",
      "40. Socktacularity Boutique Co.\n",
      "41. Socktacularity Workshop Co.\n",
      "42. Socktacularity Creative Co.\n",
      "43. Socktacularity Artistry Co.\n",
      "44. Socktacularity Design Co.\n",
      "45. Socktacularity Collection Co.\n",
      "46. Socktacularity Showroom Co.\n",
      "47. Socktacularity Emporium Co.\n",
      "48. Socktacularity Bazaar Co.\n",
      "49. Socktacularity Co.\n",
      "50. Socktacularity Shop Co.\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(\"LLM Response: \"+llm.invoke(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5586b8-4715-4abc-9352-91a5998eff7d",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def52e83-533d-4424-a8fc-40c4dd75751c",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8feb49-4c9d-434e-b944-15300e89e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9093e-7171-48dc-a319-8d142b001c95",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8f23b-b212-466f-8342-0bcb4bd6ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\",api_key=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52794a17-9fe2-4cc2-a815-dfd49c41b0ed",
   "metadata": {},
   "source": [
    "__Reference:__ [OpenAI Model List](https://platform.openai.com/docs/models), [OpenAI](https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.base.OpenAI.html), [ChatOpenAI](https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.base.OpenAI.html), [HumanMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1716cad-bfda-4e1c-81f3-5cf67d513bc3",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5fe1a-7401-442e-8fb3-2a9b3798e885",
   "metadata": {},
   "source": [
    "Most LLM applications do not pass user input directly into an LLM. Usually they will add the user input to a larger piece of text, that provides additional context on the specific task at hand so that llm can understand user input more efficiently.\n",
    "\n",
    "Typically, language models expect the prompt to either be a string or else a list of chat messages. Use `PromptTemplate` to create a template for a string prompt and `ChatPromptTemplate` to create a list of messages\n",
    "\n",
    "If the user only had to provide the description of a specific topic but not the instruction that model needs, it would be great!! PromptTemplates help with exactly this! It bundle up all the logic & instruction going from user input into a fully fromatted prompt that llm model required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a6c605d-7d38-42a7-a9ce-cefc023eda66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b20380cc-2cc6-4a13-a4ba-fee37af4a6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product'], input_types={}, partial_variables={}, template='What is a good name for a company that makes {product}?')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8afb3d6f-aba2-4eb8-820b-919b12a01d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Socktacular\\n2. Vibrant Soles\\n3. Rainbow Runners\\n4. Kaleidosock\\n5. Socktivity\\n6. Chroma Socks\\n7. Sock Candy Co.\\n8. Pop Socks\\n9. Colorful Kicks\\n10. Sock Society\\n11. Bright Sock Co.\\n12. Sock Wonders\\n13. Hue Socks\\n14. Pizzaz Socks\\n15. Sockcessories\\n16. Sockaroo\\n17. Socktacularity\\n18. Sockstars\\n19. Vibrant Vibes Socks\\n20. SockPop\\n21. Sockspectacular\\n22. Sockalicious\\n23. Socktacularity\\n24. Socktacularity Co.\\n25. Socktacularity Socks\\n26. Socktacularity Designs\\n27. Socktacularity Shop\\n28. Socktacularity Collection\\n29. Socktacularity Boutique\\n30. Socktacularity Studio\\n31. Socktacularity Gallery\\n32. Socktacularity Emporium\\n33. Socktacularity Bazaar\\n34. Socktacularity Showroom\\n35. Socktacularity Workshop\\n36. Socktacularity Creative\\n37. Socktacularity Artistry\\n38. Socktacularity Studio Co.\\n39. Socktacularity Gallery Co.\\n40. Socktacularity Boutique Co.\\n41. Socktacularity Workshop Co.\\n42. Socktacularity Creative Co.\\n43. Socktacularity Artistry Co.\\n44. Socktacularity Design Co.\\n45. Socktacularity Collection Co.\\n46. Socktacularity Showroom Co.\\n47. Socktacularity Emporium Co.\\n48. Socktacularity Bazaar Co.\\n49. Socktacularity Co.\\n50. Socktacularity Shop Co.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd124287-c2e1-44a1-b317-9e35cb6f4363",
   "metadata": {},
   "source": [
    "__Reference:__ [PromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e2a88-a321-4cf9-b451-fd265f62fc52",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate\n",
    "Each chat message is associated with content, and an additional parameter called `role`. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "681a403a-c1f9-4baf-aadd-066b93e53cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c917dab0-8bae-4c5c-867b-7eb7623a02a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b8f612c-2197-4a24-99a4-9e9db2d094e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Socktacular\\n2. Vibrant Soles\\n3. Rainbow Runners\\n4. Kaleidosock\\n5. Socktivity\\n6. Chroma Socks\\n7. Sock Candy Co.\\n8. Pop Socks\\n9. Colorful Kicks\\n10. Sock Society\\n11. Bright Sock Co.\\n12. Sock Wonders\\n13. Hue Socks\\n14. Pizzaz Socks\\n15. Sockcessories\\n16. Sockaroo\\n17. Socktacularity\\n18. Sockstars\\n19. Vibrant Vibes Socks\\n20. SockPop\\n21. Sockspectacular\\n22. Sockalicious\\n23. Socktacularity\\n24. Socktacularity Co.\\n25. Socktacularity Socks\\n26. Socktacularity Designs\\n27. Socktacularity Shop\\n28. Socktacularity Collection\\n29. Socktacularity Boutique\\n30. Socktacularity Studio\\n31. Socktacularity Gallery\\n32. Socktacularity Emporium\\n33. Socktacularity Bazaar\\n34. Socktacularity Showroom\\n35. Socktacularity Workshop\\n36. Socktacularity Creative\\n37. Socktacularity Artistry\\n38. Socktacularity Studio Co.\\n39. Socktacularity Gallery Co.\\n40. Socktacularity Boutique Co.\\n41. Socktacularity Workshop Co.\\n42. Socktacularity Creative Co.\\n43. Socktacularity Artistry Co.\\n44. Socktacularity Design Co.\\n45. Socktacularity Collection Co.\\n46. Socktacularity Showroom Co.\\n47. Socktacularity Emporium Co.\\n48. Socktacularity Bazaar Co.\\n49. Socktacularity Co.\\n50. Socktacularity Shop Co.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef1b49-bf4c-496a-baf1-ca7241c621b2",
   "metadata": {},
   "source": [
    "__Reference:__ [ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a2ee6-fd8c-4d4e-949f-c38cff8c7a2f",
   "metadata": {},
   "source": [
    "# Message Prompts\n",
    "LangChain provides different types of MessagePromptTemplate. The most commonly used are `AIMessagePromptTemplate`, `SystemMessagePromptTemplate` and `HumanMessagePromptTemplate`, which create an AI message, system message and human message respectively.\n",
    "\n",
    "All messages have a role and a content property. The role describes WHO is saying the message. The content property describes the content of the message. This can be a few different things:\n",
    "\n",
    "__Reference:__ [ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
