{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e32022-06bc-4d18-a6f1-8df8cb2a3cc9",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Random Forest is an ensemble machine learning algorithm that combines the predictions from multiple decision trees to make a more robust and accurate prediction. It’s widely used in both classification and regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af84c0c-cc07-480c-a6e4-a6cb66ceb2e7",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "1. **Ensemble Learning**: Random Forest is a type of ensemble learning where multiple models (in this case, decision trees) are trained, and their outputs are combined to achieve a more reliable result.\n",
    "2. **Decision Tree**: Each decision tree in the forest is trained independently. A decision tree is a model that splits data points based on feature values to classify or predict the target variable.\n",
    "3. **Bootstrap Sampling (Bagging)**: Random Forest uses bootstrap sampling, also known as \"bagging,\" to train each decision tree on a different subset of data. This subset is randomly chosen with replacement, meaning some data points can appear more than once in the subset, while others may not appear at all.\n",
    "4. **Random Feature Selection**: For each tree, Random Forest selects a random subset of features at each split rather than considering all features, which reduces correlation between trees and helps prevent overfitting.\n",
    "5. **Voting or Averaging**: In classification, Random Forest makes predictions based on majority voting across all decision trees. In regression, the final prediction is typically the average of all tree predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189ac6e-fb73-40db-89dc-358f38173f1e",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. **Data Sampling**: Randomly sample the training data with replacement to create multiple datasets.\n",
    "2. **Build Decision Trees**: For each sampled dataset, build a decision tree:\n",
    "    - Use a random subset of features at each split.\n",
    "    - Grow the tree to its maximum depth (or until other stopping criteria are met).\n",
    "3. **Combine Results**:\n",
    "    - In classification, each tree casts a “vote,” and the class receiving the most votes becomes the final prediction.\n",
    "    - In regression, the final prediction is the average of the predictions made by each tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
